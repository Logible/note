# 基础概念

- [基础概念](#基础概念)
  - [基本](#基本)
  - [density estimation and resolution](#density-estimation-and-resolution)
  - [A "reweighted objective"](#a-reweighted-objective)
  - [sample quality](#sample-quality)
  - [inductive model](#inductive-model)
  - [underlying neural backbone](#underlying-neural-backbone)
  - [3.1. Perceptual Image Compression](#31-perceptual-image-compression)


## 基本

在训练方式上，DMs相较于GAN有着较大的差别，通过**对原始数据进行加噪使其接近高斯分布**，再利用神经网络去除图像中的噪声以实现图像生成，另外，神经网络能够**学习到原始图像的数据分布**，因此能够实现对原始图像数据做小的修改而实现更加多样化的图像生成。

- 扩散模型涉及两个互关联的过程，分别是前向过程与反向过程。

  - 前向过程将数据分布转换为更简单的先验分布，例如高斯分布；
  - 反向过程，利用经过训练的神经网络，通过**模拟普通或随机微分方程**实现前向过程逆过程[9]。

- Diffusion happens in multiple steps, each step operates on an input latents array, and **produces another latents array that better resembles the input text and all the visual information** the model picked up from all images the model was trained on.

## density estimation and resolution

- **density estimation**: Density estimation in the context of generative models is the **process of modeling the probability distribution of the data.** It involves understanding how likely different types of data are, which helps in generating new samples that are similar to the original dataset.

## A "reweighted objective" 

- refers to modifying the standard training objective or loss function by applying different weights **to certain parts of the data or certain aspects of the model's output.** 

## sample quality

- "sample quality"指的是生成的样本（例如图像或文本）的质量。

## inductive model

The term "inductive biases of image-like data" refers to **the inherent assumptions or predispositions that a machine learning model**, particularly one based on a UNet architecture, **has** when dealing with data that has characteristics similar to images. These biases influence how the model processes and learns from the data. 

**Spatial Hierarchies**: UNet, with its encoder-decoder structure, naturally captures the hierarchical spatial structure of images. It learns to **recognize patterns at different scales and locations**, which is crucial for understanding image-like data.

## underlying neural backbone

particularly when referring to **a UNet architecture,** describes the fundamental neural network structure that forms the core or the base of the model

## 3.1. Perceptual Image Compression

- **a perceptual loss function**
  - aims to preserve texture and other details that are perceptually significant to humans.
-  **a patch-based approach**
  -  assesses small parts or "patches" of the image. This method helps in focusing on local details and textures, enabling the autoencoder to generate images that are more realistic and have higher local fidelity.
- **Downsampling**: Downsampling is the process of reducing the resolution of an image. It involves decreasing the height and width of the image, thus reducing the total number of pixels.
- **High-variance latent spaces**
  -  a characteristic of the latent space in a generative model where **the representations (latent variables) have a large amount of variability or spread**. 
  - similar inputs may have **very different representations** in the latent space, 
- VAE(Variational Autoencoder)
  - VAEs are particularly known for their use of probabilistic encoders and decoders, which map **inputs to distributions over the latent space**, rather than deterministic points.
  - This KL penalty encourages the latent space **to approximate a chosen prior distribution**, often **a standard normal distribution** (a normal distribution with a mean of zero and a variance of one). 
  - By imposing this penalty, **VAEs aim to have a well-structured latent space** where similar inputs are encoded to similar points in the latent space, and where sampling from the latent space can generate realistic outputs.
- VQ
  - 向量量化（Vector Quantization, VQ）层是神经网络中的一种特殊层，它在编码器和解码器之间进行操作，将连续的潜在空间表示转换为离散的表示。具体来说，它涉及以下步骤：

    1.  **量化代码本**: 在训练之初，定义一组离散的向量，这些向量组成了一个“代码本”或“字典”。这个代码本包含了多个向量，每个向量可以看作是潜在空间的一个“代码点”或“中心”。
    2.  **最近邻搜索**: 编码器输出一个连续的潜在向量。向量量化层接收这个连续向量，并在代码本中寻找与之距离最近的代码点。  
    3.  **映射**: 一旦找到最近的代码点，原始的连续向量就会被这个代码点替换，实现了向量的量化。这意味着，无论编码器的输出有多细微的变化，只要它们离同一个代码点最近，就会被量化成相同的向量
- a "two-dimensional structure"
  - refers to the width and height dimensions of an image or a feature map. If the latent space `z` retains this two-dimensional structure, it implies that the model **preserves spatial relationships and structures** that are present in the original image data, instead of flattening them into a one-dimensional vector.

