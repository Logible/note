# Deciding what to try next

- [Deciding what to try next](#deciding-what-to-try-next)
  - [Evaluating a model](#evaluating-a-model)
  - [Model selection and training/cross validation/test sets](#model-selection-and-trainingcross-validationtest-sets)
  - [Diagnosing bias and variance](#diagnosing-bias-and-variance)
    - [Learning Curves](#learning-curves)
  - [Deciding what to try next for bias and variance](#deciding-what-to-try-next-for-bias-and-variance)
  - [Bias/variance and neural networks](#biasvariance-and-neural-networks)
  - [Machine learning development process](#machine-learning-development-process)
  - [Error analysis](#error-analysis)
  - [Adding data](#adding-data)
  - [Transfer learning: using datafrom a different task](#transfer-learning-using-datafrom-a-different-task)

## Evaluating a model

- Train/test procedure for linear regression (with squared error cost)
  - ![20231001155957](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001155957.png)
  - Train/test![20231001160311](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001160311.png)
- Train/test procedure for classification problem![20231001161123](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001161123.png)

## Model selection and training/cross validation/test sets

- Cross-validation: that this is an extra dataset that we're going to use to check or trust check the validity or really the accuracy of different models.

  ![20231001163927](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001163927.png)

- choosing a neural network architecture
  - ![20231001165156](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001165156.png)
  - ![20231001164658](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001164658.png)

## Diagnosing bias and variance

- bias and variance![20231001170802](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001170802.png)
- high bias and variance![20231001171554](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001171554.png)
- exmaple![Alt text](images/image-5.png)

### Learning Curves

- ![20231001205420](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001205420.png)
- High bias![20231001210257](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001210257.png)
- High Variance![Alt text](images/image-6.png)

## Deciding what to try next for bias and variance

- ![20231001215002](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001215002.png)

## Bias/variance and neural networks

- ![20231001225836](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001225836.png)
- It hardly ever hurts to have a larger neural network so long as you regularize appropriately.![Alt text](images/image-8.png)
- Neural network regularization![20231001231136](https://raw.githubusercontent.com/Logible/Image/main/note_image/20231001231136.png)

## Machine learning development process

- Iterative loop of ML development![Alt text](images/image-9.png)
- Example: Buiding a spam classifier
  - ![Alt text](images/image-10.png)
  - ![Alt text](images/image-11.png)

## Error analysis

- ![Alt text](images/image-12.png)

## Adding data

- Data augmentation
  - ![Alt text](images/image-13.png)
  - ![Alt text](images/image-14.png)
- Data augmentation by introducing distortions
  - ![Alt text](images/image-15.png)
- Data synthesis
  - ![OCR](images/image-16.png)

## Transfer learning: using datafrom a different task
