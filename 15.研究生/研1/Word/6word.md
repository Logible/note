# 6

## 10-30

1. because this looks like really **warped** fours
2. **nudge** it to the left to get theta minus epsilon
3. applying machine learning is a highly **empirical** process
4. So that's why you get these **oscillations**
5. And the noisiness can be **ameliorated** or can be reduced by just using a smaller learning rate.
6. So, there's just a bit more **latency**

## 10-31

1. So this type of a **coarse to fine** search is also frequently used.
2. I've seen that intuitions do get **stale**
3. that is watching performance and patiently **nudging** the learning rate up or down

## 11-01

1. we call it Z **tilde~**
2. the need to retrain your function becomes even more **acute**
3. that performs element-wise **exponentiation**
4. lt makes it relatively **interpretable**
5. get closer and closer to hitting the **bullseye**
6. the point was with the **philosophy** of orthogonalization
7. **whereupon** you might no longer have a good estimate of Bayes error

## 11-02

1. There is one **caveat** to this
2. maybe even blurrier because it's shot by **amateur** users
3. professionally framed, high **resolution**, onally taken images of cats
4. But you now have a bit of a **dilemma**
5. And for **the sake of argument**
6. So, in order to **tease out** these two effects
7. very **impoverished** synthesized data set from
8. both are useful tools to have in your **arsenal**
9. it just lets you through without needing you to carry an RFID **badge**
10. This is a **turnstile** that is giving employees access to a workplace.
11. So machine learning researchers tend to speak **disparagingly** of hano designing things

## 11-03

1. doing well on the training set is usually a **prerequisite** to doing well on your hold out
2. Local warping
3. in case you think I'm being **derogatory** of hand engineering