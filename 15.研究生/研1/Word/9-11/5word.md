# 5

## 10-24

1. to pre **populate** the matrix A with the numbers we had just now
2. Feel free to **toss** a lot of assert() statements
3. But, anything **to the power of** 0 is equal to 1, so that goes away
4. so this is **analogous** to how in logistic regression
5. So that's how the square bracket and the round bracket **indices** work.
6. And by the way, in case it seems like I'm getting a lot of **nitty** **gritty** linear algebra
7. I'm just going to give away the **punchline** and tell you what you need to implement 
8. but for your application with your applications **idiosyncrasy**
9. the little **dash** on top is called **prime**

## 10-27

1. a **comma** y
2. when we talk about full **fledged** neural networks

## 10-29

1. which causes your tanh or a sigmoid activation function to be **saturated**
2. that you're **uttering**, in order to carry out speech recognition
3. evaluate them on a hold out **cross-validation** set or something
4. In this first week, we'll first talk about the **cellular** machine learning problem
5. **And in a similar vein**, the main goal of your test set is, given your fina classifier
6. this example is a little bit **contrived** in two dimensions
