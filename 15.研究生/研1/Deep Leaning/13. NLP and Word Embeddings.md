# NLP and Word Embeddings

- [NLP and Word Embeddings](#nlp-and-word-embeddings)
  - [Word representation](#word-representation)
  - [Using word embeddings](#using-word-embeddings)
  - [Properties of word embeddings](#properties-of-word-embeddings)
  - [Embedding matrix](#embedding-matrix)
  - [Learning word embeddings](#learning-word-embeddings)
  - [Word2Vec](#word2vec)
  - [Negative sampling](#negative-sampling)
  - [GloVe word vectors](#glove-word-vectors)
  - [Sentiment classification](#sentiment-classification)
  - [Debiasing word embeddings](#debiasing-word-embeddings)

## Word representation

- Word representation
  - ![Alt text](images/image-279.png)
- Featurized representation: word embedding
  - a 300 dimensional vector for representing the word man.
  - ![Alt text](images/image-280.png)
- Visualizing word embeddings
  - ![Alt text](images/image-281.png)

## Using word embeddings

- Named entity recognition example
  - And by examining tons of unlabeled text, learn embeddings then groups them together
  - ![Alt text](images/image-282.png)
- Transfer learning and word embeddings
  - ![Alt text](images/image-283.png)
- Relation to face encoding
  - ![Alt text](images/image-284.png)

## Properties of word embeddings

- Analogies
  - ![Alt text](images/image-285.png)
- Analogies using word vectors
  - ![Alt text](images/image-286.png)
- Cosine similarity
  - ![Alt text](images/image-287.png)

## Embedding matrix

- Embedding matrix
  - ![Alt text](images/image-288.png)

## Learning word embeddings

- Neural language model
- the parameters of this model will be this matrix E,W,b,
- maximize the likelihood of your training set
  - ![Alt text](images/image-289.png)

- Other context/target pairs
  - ![Alt text](images/image-290.png)

## Word2Vec

- Model
  - ![Alt text](images/image-291.png)
- Problems with softmax classification
- hierarchical softmax classifier
  - ![Alt text](images/image-292.png)

## Negative sampling

- Defining a new learning problem
  - ![Alt text](images/image-312.png)
- Model
  - k to 1 ratio of negative to positive examples
  - ![Alt text](images/image-293.png)
- Selecting negative examples
  - ![Alt text](images/image-294.png)

## GloVe word vectors

- GloVe (global vectors for word representation)
  - ![Alt text](images/image-295.png)
- Model
  - theta and e in this particular formulation play symmetric roles
  - ![Alt text](images/image-296.png)
- A note on the featurization view of word embeddings
  - ![Alt text](images/image-297.png)

## Sentiment classification

- Sentiment classification problem
  - ![Alt text](images/image-298.png)
- Simple sentiment classification model
  - ![Alt text](images/image-299.png)
- RNN for sentiment classification
  - ![Alt text](images/image-300.png)

## Debiasing word embeddings

- The problem of bias in word embeddings
  - ![Alt text](images/image-301.png)
- Addressing bias in word embeddings
  - ![Alt text](images/image-302.png)