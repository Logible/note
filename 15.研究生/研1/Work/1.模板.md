# 模板

- 解压图片
  - ffmpeg -i ⭐.mp4 -vf "select=not(mod(n\,1))" -vsync 0 ⭐/%05d.png
  - ffmpeg -i ⭐.mp4 -start_number ⭐ -vf "select=between(n\,⭐\,⭐)" -vsync 0 ./%05d.png

- 抠图
  - python main.py --img_dir ⭐ --out_dir ⭐ --color cg --bg ⭐ --multi_process 20 --mask_th ⭐
- 阈值抠图
  - python main.py --img_dir ⭐ --out_dir ⭐ --color g --multi_process 5 --upper ⭐ --lower ⭐ 

- 合成视频
  - python get_seg_video3.py ---path ⭐/ --video_file ⭐.mp4 --start_id 1 --end_id -1

- 删除文件
  - rm -rf ./⭐/

- 切换


cd /data9/log/video-preprocessing
conda activate testYoutu

cd /data/log/DaGAN_Serve
conda activate myenv

cd /data/log/bg-segment
conda activate myenv

cd /data/log/DaGAN/CVPR2022-DaGAN
conda activate modelscope

- 查看文件大小
  - ls -lh ⭐

- 查看文件夹数量
  - ls -1 ⭐ | wc -l

- du -sh /data/*
  - 查看data下文件夹使用情况

- df -h
  - 查看磁盘使用情况

- 挂在进程在后台
  - nohup python ⭐.py > output.log 2>&1 &

   * `> output.log`: Redirect standard output (stdout) to a file named `output.log`.
   * `2>&1`: Redirect standard error (stderr) to the same location as stdout (in this case, `output.log`).
   * `&`: Run the command in the background.

- conda config --show channels

- 当前conda路径
  - echo $CONDA_PREFIX$
- 当前conda包
  - conda list

- pip -i
  - -i https://pypi.tuna.tsinghua.edu.cn/simple

- ls /proc/880585 -lh

- git clone
  - --server-option 192.168.110.84

- 跨
  - sudo scp -P 56000 -r /data/log/crop-video __su@10.112.226.54:/data/log/

## 1110

ffmpeg -i /data/log/1110/陈/chen_1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1110/陈/chen_1/%05d.png
ffmpeg -i /data/log/1110/陈/chen_2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1110/陈/chen_2/%05d.png

python main.py --img_dir /data/log/1110/陈/chen_1/ --out_dir /data/log/1110/陈/chen_1_mask100/ --color cg --bg /data/log/1110/陈/c.png --multi_process 20 --mask_th 100
python main.py --img_dir /data/log/1110/陈/chen_2/ --out_dir /data/log/1110/陈/chen_2_mask100/ --color cg --bg /data/log/1110/陈/c.png --multi_process 5 --mask_th 100

python get_seg_video3.py ---path /data/log/1110/陈/chen_1_mask100/ --video_file /data/log/1110/陈/chen_1_mask100.mp4 --start_id 1 --end_id 1000
python get_seg_video3.py ---path /data/log/1110/陈/chen_2_mask100/ --video_file /data/log/1110/陈/chen_2_mask100.mp4 --start_id 1 --end_id -1

--- 

ffmpeg -i /data/log/1110/金可/jk_1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1110/金可/jk_1/%05d.png
ffmpeg -i /data/log/1110/金可/jk_2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1110/金可/jk_2/%05d.png

python main.py --img_dir /data/log/1110/金可/jk_1/ --out_dir /data/log/1110/金可/jk_1_mask100 --color cg --bg /data/log/1110/金可/jk.png --multi_process 12 --mask_th 100
python main.py --img_dir /data/log/1110/金可/jk_2/ --out_dir /data/log/1110/金可/jk_2_mask100 --color cg --bg /data/log/1110/金可/jk.png --multi_process 20 --mask_th 100

python get_seg_video3.py ---path /data/log/1110/金可/jk_1_mask100 --video_file /data/log/1110/金可/jk_1_mask100.mp4 --start_id 1 --end_id 1500
python get_seg_video3.py ---path /data/log/1110/金可/jk_2_thres/ --video_file /data/log/1110/金可/jk_2_thres.mp4 --start_id 1 --end_id 700

## 1113

python main.py --img_dir /data/log/1110/金可/jk_1/ --out_dir /data/log/1110/金可/jk_1_threshold --color g --multi_process 5 --upper 120,255,229 --lower 43,93,2

--img_dir G:\Video_Dispose\1110\jk\jk_1_ori --out_dir ../outs --color g --multi_process 0  --upper 135,255,229 --lower 43,172,1 --bg G:\Video_Dispose\1110\jk\jk.png

--img_dir G:\Video_Dispose\1110\jk\jk_2_ori --out_dir ./outs --color g --multi_process 0  --upper 70,221,230 --lower 42,170,74 --bg G:\Video_Dispose\1110\jk\jk.png

--img_dir G:\Video_Dispose\1110\jk\jk_2_ori --out_dir ./outs --color g --multi_process 0  --upper 70,255,230 --lower 42,170,59 --bg G:\Video_Dispose\1110\jk\jk.png


- 越小，扣的越少（绿色越多

python main.py --img_dir /data/log/1110/金可/jk_2/ --out_dir /data/log/1110/金可/jk_2_mask0new --color cg --bg /data/log/1110/金可/jk_new.png --multi_process 20 --mask_th 0

python main.py --img_dir /data/log/1110/金可/jk_1/ --out_dir /data/log/1110/金可/jk_1_threshold2 --color g --multi_process 5 --bg /data/log/1110/金可/jk.png --upper 135,255,229 --lower 43,172,1

python main.py --img_dir /data/log/1110/金可/jk_2/ --out_dir /data/log/1110/金可/jk_2_thres --color g --multi_process 20  --upper 70,255,230 --lower 42,170,59 --bg /data/log/1110/金可/jk.png

## 1113

1. ffmpeg -i /data/log/1113/tingting.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1113/tingting/%05d.png
2. python main.py --img_dir /data/log/1113/tingting/ --out_dir /data/log/1113/tingting_dis --color cg --bg /data/log/1113/ting.png  --multi_process 20 --mask_th 100

## 1114

python get_seg_video3.py ---path /data/log/1110/金可/jk_1_threshold2/ --video_file /data/log/1110/金可/jk_1_threshold2.mp4 --start_id 1 --end_id -1

mkdir FengYang1 FengYang2 FengYang3

ffmpeg -i /data/log/1114/FengYang1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1114/FengYang1/%05d.png
ffmpeg -i /data/log/1114/FengYang2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1114/FengYang2/%05d.png
ffmpeg -i /data/log/1114/FengYang3.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1114/FengYang3/%05d.png

python main.py --img_dir /data/log/1114/FengYang1/ --out_dir /data/log/1114/FengYang1_100/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100
python main.py --img_dir /data/log/1114/FengYang2/ --out_dir /data/log/1114/FengYang1_200/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100
python main.py --img_dir /data/log/1114/FengYang3/ --out_dir /data/log/1114/FengYang1_300/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100

---

ffmpeg -i /data/log/1114/XiaoMeng.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1114/XiaoMeng/%05d.png

python main.py --img_dir /data/log/1114/XiaoMeng/ --out_dir /data/log/1114/XiaoMeng_100/ --color cg --bg /data/log/1114/XiaoMengPic.png --multi_process 25 --mask_th 100

---

ffmpeg -i /data/log/1114/jk_2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1114/jk_2/%05d.png

python main.py --img_dir /data/log/1114/jk_2/ --out_dir /data/log/1114/jk_2_thres_oc --color g --multi_process 30  --upper 70,255,230 --lower 42,170,59 --bg /data/log/1114/jk.png

rm -rf ./FengYang1/*
rm -rf ./FengYang2/*
rm -rf ./FengYang3/*
rm -rf ./FengYang1/*

10621-12694
624-2485
3761-5566

ffmpeg -i /data/log/1114/FengYang1.mp4 -start_number 10621 -vf "select=between(n\,10621\,12694)" -vsync 0 /data/log/1114/FengYang1/%05d.png
ffmpeg -i /data/log/1114/FengYang2.mp4 -start_number 624 -vf "select=between(n\,624\,2485)" -vsync 0 /data/log/1114/FengYang2/%05d.png
ffmpeg -i /data/log/1114/FengYang3.mp4 -start_number 3761 -vf "select=between(n\,3761\,5566)" -vsync 0 /data/log/1114/FengYang3/%05d.png

python main.py --img_dir /data/log/1114/FengYang1/ --out_dir /data/log/1114/FengYang1_100/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100
python main.py --img_dir /data/log/1114/FengYang2/ --out_dir /data/log/1114/FengYang2_100/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100
python main.py --img_dir /data/log/1114/FengYang3/ --out_dir /data/log/1114/FengYang3_100/ --color cg --bg /data/log/1114/FengYangPic.png --multi_process 6 --mask_th 100

python get_seg_video3.py ---path /data/log/1114/FengYang1_100/ --video_file /data/log/1114/FengYang1_100.mp4 --start_id 1 --end_id -1
python get_seg_video3.py ---path /data/log/1114/FengYang2_100/ --video_file /data/log/1114/FengYang2_100.mp4 --start_id 1 --end_id -1
python get_seg_video3.py ---path /data/log/1114/FengYang3_100/ --video_file /data/log/1114/FengYang3_100.mp4 --start_id 1 --end_id -1

rm ./000{01..36}.png
rm ./00{624..635}.png

rm ./0{7323..7633}.png

python get_seg_video3.py ---path /data/log/1114/XiaoMeng_100/ --video_file /data/log/1114/XiaoMeng_100.mp4 --start_id 1 --end_id -1

## 1115

python get_seg_video3.py ---path /data/log/1114/jk_2_thres/ --video_file /data/log/1114/jk_2.mp4 --start_id 1 --end_id -1

python get_seg_video3.py ---path /data/log/1114/XiaoMeng_100/ --video_file /data/log/1114/XiaoMeng_100.mp4 --start_id 1 --end_id -1

## 1117

upper指高阈值，lower低阈值

- no3

--upper
48,229,246
--lower
44,172,143

- no4

--upper
48,222,252
--lower
44,164,178

## 1122

ffmpeg -i /data/log/1122/145457.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1122/145457/%05d.png

python main.py --img_dir /data/log/1122/145457 --out_dir /data/log/1122/145457_dis --color cg --bg /data/log/1122/pic.png --multi_process 20 --mask_th 150

python get_seg_video3.py ---path /data/log/1122/145457_dis/ --video_file /data/log/1122/145457_dis.mp4 --start_id 1 --end_id -1

## 1123

ffmpeg -i /data/log/1123/jk_1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/1123/jk_1/%05d.png

python main.py --img_dir /data/log/1123/jk_1/ --out_dir /data/log/1123/jk_1123/ --color cg --bg /data/log/1123/jk_bg.png --multi_process 20 --mask_th 150

python main.py --img_dir /data/log/1123/jk_1/ --out_dir /data/log/1123/jk_1123_g/ --color g --bg /data/log/1123/jk_bg.png --multi_process 20 --mask_th 150 --upper 50,255,246 --lower 43,135,81

## 1207

- ffmpeg -i G:\Video_Dispose\1207\v.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\Video_Dispose\1207\img\%05d.png

--img_dir
G:\Video_Dispose\1207\img
--out_dir
G:\Video_Dispose\1207\img_dis
--color
g
--multi_process
0
--upper
73,255,172
--lower
63,114,50


## DaGAN

- /data/log/DaGAN/DaGANTest/testVideo.mp4
- /data/log/DaGAN/DaGANTest/DingZhen

python crop-video.py --inp "/data/log/DaGAN/DaGANTest/testVideo.mp4"

python crop-video.py --inp "/data/log/DaGAN/DaGANTest/DingZhen.jpg"

ffmpeg -i /data/log/DaGAN/DaGANTest/testVideo.mp4 -ss 0.0 -t 92.68 -filter:v "crop=337:337:371:411, scale=256:256" /data/log/DaGAN/DaGANTest/crop.mp4

python demo.py  --config config/vox-adv-256.yaml --driving_video G:\dataset\DaGANTest\crop.mp4 --source_image G:\dataset\DaGANTest\testDingZhen.png --checkpoint G:\DownLoad\CVPR22_DaGAN\DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

python demo.py  --config config/vox-adv-256.yaml --driving_video /data/log/DaGAN/DaGANTest/crop.mp4 --source_image /data/log/DaGAN/DaGANTest/log.png --checkpoint /data/log/DaGAN/DaGANTest/CVPR22_DaGAN/DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

torchaudio==0.10.1+rocm4.1

set http_proxy=192.168.110.84
set https_proxy=192.168.110.84

## 1-11

python demo.py  --config config/vox-adv-256.yaml --driving_video /data/log/DaGAN/DaGANTest/crop.mp4 --source_image /data/log/DaGAN/DaGANTest/log.png --checkpoint /data/log/DaGAN/DaGANTest/CVPR22_DaGAN/DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

python main.py --img_dir /data/log/1123/jk_1/ --out_dir /data/log/1123/jk_1123/ --color cg --bg /data/log/1123/jk_bg.png --multi_process 20 --mask_th 150

ls -lh /data9/caijiaran/debug_data/519_video/01.mp4

cp /data9/caijiaran/debug_data/520_video/01.mp4 /data/log/0111/02.mp4

ffmpeg -i /data/log/0111/01.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/0111/01/%05d.png

ffmpeg -i /data/log/0111/02.mp4 -vf "select=not(mod(n\,1))" -vsync 0 /data/log/0111/02/%05d.png

CUDA_VISIBLE_DEVICES=0 python main.py --img_dir /data/log/0111/01 --out_dir /data/log/0111/01_dis --color cg --bg /data/log/0111/01bg.png --multi_process 30 --mask_th 150

CUDA_VISIBLE_DEVICES=1 python main.py --img_dir /data/log/0111/02 --out_dir /data/log/0111/02_dis --color cg --bg /data/log/0111/02bg.png  --multi_process 30 --mask_th 150

/data/log/0111/01_dis/
/data/log/0111/02_dis/

## 1-16

python demo.py  --config G:\code\CVPR2022-DaGAN\config\vox-adv-256.yaml --driving_video G:\dataset\DaGANTest\crop.mp4 --source_image G:\dataset\DaGANTest\testDingZhen.png --checkpoint G:\DownLoad\CVPR22_DaGAN\DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

conda DaGAN create -f G:\env\DaGAN\environment.yml

python demo.py  --config G:\code\CVPR2022-DaGAN\config\vox-adv-256.yaml --driving_video G:\dataset\DaGANTest\crop.mp4 --source_image G:\dataset\DaGANTest\testDingZhen.png --checkpoint G:\DownLoad\CVPR22_DaGAN\DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

python demo.py  --config config/vox-adv-256.yaml --driving_video G:\dataset\DaGANTest\crop.mp4 --source_image G:\dataset\DaGANTest\testDingZhen.png --checkpoint G:\dataset\FOMM\vox-adv-cpk.pth.tar --relative --adapt_scale

## 1-19

- ffmpeg -i 01.mp4 -start_number 1 -vf "select=between(n\,1\,1000)" -vsync 0 ./img/%05d.png
- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/dis_img --color cg --bg /data/log/0119/bg.png --multi_process 20 --mask_th 20
- python get_seg_video3.py ---path /data/log/0119/dis_img/ --video_file /data/log/0119/dis_img.mp4 --start_id 1 --end_id -1

- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/dis_img_150 --color cg --bg /data/log/0119/bg.png --multi_process 30 --mask_th 150
- python get_seg_video3.py ---path /data/log/0119/dis_img_150/ --video_file /data/log/0119/dis_150.mp4 --start_id 1 --end_id -1

- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/dis_img_250 --color cg --bg /data/log/0119/bg.png --multi_process 30 --mask_th 250
- python get_seg_video3.py ---path /data/log/0119/dis_img_250/ --video_file /data/log/0119/dis_250.mp4 --start_id 1 --end_id 400

- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/green_img --color g --multi_process 5 --upper 73,228,178 --lower 55,95,51
- python get_seg_video3.py ---path /data/log/0119/green_img --video_file /data/log/0119/green_img.mp4 --start_id 1 --end_id 500

- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/green_strong --color g --multi_process 5 --upper 75,228,178 --lower 55,45,39
- python get_seg_video3.py ---path /data/log/0119/green_strong --video_file /data/log/0119/green_strong.mp4 --start_id 1 --end_id 500

- python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/green_strong_2 --color g --multi_process 30 
--upper 78,255,178 --lower 49,36,32
- python get_seg_video3.py ---path /data/log/0119/green_strong_2 --video_file /data/log/0119/green_strong_2.mp4 --start_id 1 --end_id -1

- cp /data9/mxp/dataset/lingxi_LiveStreaming_dataset
- cp -r /data9/mxp/dataset/lingxi_LiveStreaming_dataset/* video_pickup/

## 0121

python run.py --config config/vox.yaml --mode animate --checkpoint G:\dataset\FOMM\vox-adv-cpk.pth.tar

## 0122

python crop-video.py --inp "G:\dataset\DaGANTest\testVideo.mp4"

python crop-video-single.py --inp "/data/log/DaGAN/DaGANTest/huazhiji_0.mp4"

python crop-video-single.py --inp G:\dataset\video_pick\cut.mp4

- ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 0.0 -t 55.36666666666667 -filter:v "crop=343:343:348:349, scale=256:256" crop1.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 55.4 -t 6.333333333333336 -filter:v "crop=279:279:263:375, scale=256:256" crop2.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 61.766666666666666 -t 9.900000000000006 -filter:v "crop=345:345:202:371, scale=256:256" crop3.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 71.7 -t 14.299999999999997 -filter:v "crop=318:317:330:359, scale=256:256" crop4.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 95.3 -t 6.6000000000000085 -filter:v "crop=332:332:203:342, scale=256:256" crop5.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 108.8 -t 22.966666666666683 -filter:v "crop=282:282:324:388, scale=256:256" crop6.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 136.3 -t 9.466666666666669 -filter:v "crop=335:335:284:354, scale=256:256" crop7.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 145.8 -t 25.866666666666646 -filter:v "crop=347:347:313:350, scale=256:256" crop8.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 171.7 -t 8.166666666666686 -filter:v "crop=310:309:216:367, scale=256:256" crop9.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 179.9 -t 9.666666666666657 -filter:v "crop=326:327:182:364, scale=256:256" crop10.mp
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 190.36666666666667 -t 26.03333333333333 -filter:v "crop=330:329:488:378, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 225.06666666666666 -t 22.066666666666663 -filter:v "crop=340:340:538:377, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 267.6 -t 12.0 -filter:v "crop=271:271:400:402, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 297.3666666666667 -t 12.699999999999989 -filter:v "crop=301:301:438:375, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 311.1 -t 7.633333333333326 -filter:v "crop=287:287:290:366, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 321.53333333333336 -t 19.799999999999955 -filter:v "crop=280:280:396:403, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 357.43333333333334 -t 35.06666666666666 -filter:v "crop=326:326:425:375, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 392.96666666666664 -t 14.366666666666674 -filter:v "crop=310:310:276:379, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 407.3666666666667 -t 7.800000000000011 -filter:v "crop=267:267:379:411, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 416.8666666666667 -t 8.699999999999989 -filter:v "crop=283:283:274:372, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 429.6666666666667 -t 12.033333333333303 -filter:v "crop=306:307:354:370, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 447.43333333333334 -t 18.73333333333335 -filter:v "crop=312:311:307:376, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 466.2 -t 5.600000000000023 -filter:v "crop=264:264:362:412, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 473.06666666666666 -t 10.266666666666652 -filter:v "crop=314:313:231:380, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 483.76666666666665 -t 10.900000000000034 -filter:v "crop=356:356:365:356, scale=256:256" crop.mp4
  ffmpeg -i /data/log/DaGAN/DaGANTest/huazhiji_0.mp4 -ss 494.7 -t 16.466666666666697 -filter:v "crop=271:271:358:406, scale=256:256" crop.mp4

## 0123

conda create --name facefusion python=3.10

conda create --name video_env --clone myenv

ffmpeg -i G:\dataset\video_pick\cut.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\dataset\video_pick\yolo\%05d.png

## 0124

du -sh /data/log/*

https://youtu.be/aTUWGC7lEU4?si=Pu8FH2whT12NMqZp

sudo wget https://yt-dl.org/downloads/latest/youtube-dl -O youtube-dl

## 0125

conda create -n testYoutu python=3.8

pip install scikit-image==0.2.0

du -sh /data/log/*

## 0126

ls -1 /data/log/video-preprocessing/vox | wc -l

mv video_pickup/* /data9/log/video_pickup

cp /data/log/video-preprocessing/* /data9/log/video-preprocessing/
cp -r /data/log/video-preprocessing/* /data9/log/video-preprocessing/

CUDA_VISIBLE_DEVICES=1 python load_videos.py --metadata vox-metadata.csv --format .png --out_folder vox --workers 8

du -sh /data9/log/*

cp -r /data/keith/face_occlusion_prediction/* /data/log/face_occlusion_prediction

cp -r /data9/mxp/dataset/lingxi_LiveStreaming_dataset/video_new/* /data9/log/video_pick

nohup python load_videos.py --metadata vox-metadata.csv --format .png --out_folder vox --workers 8 > output.log 2>&1 &

ffmpeg -i G:\dataset\video_pick\crop_cut1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 

G:\dataset\video_pick\crop_cut1\%05d.png


Delete:: ; 当 Delete 键被按下时
    Click ; 模拟点击鼠标左键（连续两次）
return

ffmpeg -i G:\dataset\video_pick\crop_cut2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\dataset\video_pick\crop_cut2\crop_cut2_%05d.png

python crop-video-single.py --inp G:\dataset\video_pick\guoquan_cut.mp4

python run.py --config config/vox.yaml --mode animate --checkpoint G:\dataset\FOMM\vox-adv-cpk.pth.tar

ps -ef | grep 2222355

## 0128

du -sh /data9/log/*

scp __su@10.112.144.132:/data9/log/video-preprocessing/output.log E:\vox_git

ls -1 /data9/log/video-preprocessing/vox/test | wc -l

python run.py --config config/dataset_name.yaml --mode reconstruction --checkpoint path/to/checkpoint

python run.py --config config/vox.yaml --mode reconstruction --checkpoint G:\dataset\FOMM\vox-adv-cpk.pth.tar

/data/log/pose-evaluation/testData/

python extract.py --in_folder /data/log/pose-evaluation/testData --out_file pose_gt.pkl --is_video --type face_pose --image_shape 256,256
python extract.py --in_folder /data/log/pose-evaluation/testData2 --out_file pose_gen.pkl --is_video --type face_pose --image_shape 256,256
python cmp_kp.py pose_gt.pkl pose_gen.pkl

python extract.py --in_folder E:\VOX\test\01 --out_file pose_gt.pkl --is_video --type face_pose --image_shape 256,256

---

python extract.py --in_folder /data/log/pose-evaluation/testData --out_file id_gt.pkl --is_video --type face_id --image_shape 256,256
python extract.py --in_folder /data/log/pose-evaluation/testData2 --out_file id_gen.pkl --is_video --type face_id --image_shape 256,256
python cmp.py id_gt.pkl id_gen.pkl

conda create --name metric_env --clone myenv

/mnt/e/vox_full/train

rsync -avz --progress __su@10.112.144.132:/data9/log/video-preprocessing/output.log /mnt/e/vox_full/train

ssh __su@10.112.144.132

ssh log@192.168.38.11

sudo nano /etc/hostname

## 1-29

python crop-video-single.py --inp G:\dataset\video_pick\guoquan_cut.mp4

python run.py --config config/vox.yaml --mode animate --checkpoint G:\DownLoad\CVPR22_DaGAN\DaGAN_vox_adv_256.pth.tar

- it is wrong
  - python demo.py  --config config/vox-adv-256.yaml --driving_video /data/log/DaGAN/DaGANTest/crop.mp4 --source_image /data/log/DaGAN/DaGANTest/log.png --checkpoint /data/log/DaGAN/DaGANTest/CVPR22_DaGAN/vox-adv-cpk.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator

CUDA_VISIBLE_DEVICES=0 python run_dataparallel.py --config config/vox-adv-256.yaml --device_ids 0 --name DaGAN_voxceleb2_depth --rgbd --batchsize 48 --kp_num 15 --generator DepthAwareGenerator

python crop-video-single.py --inp G:\dataset\video_pick\bug.mp4

CUDA_VISIBLE_DEVICES=0,1,2 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0,1,2 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

tensorboard --logdir /data/log/DaGAN/CVPR2022-DaGAN/log/vox_serveDaGAN_voxceleb2_depth/log

ffmpeg -i G:\dataset\video_pick\pickup\crop1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\dataset\video_pick\crop_cut2\guoquan_crop1%05d.png

ffmpeg -i G:\dataset\video_pick\pickup\crop2.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\dataset\video_pick\crop_cut2\guoquan_crop2%05d.png

ffmpeg -i G:\dataset\video_pick\pickup\crop1.mp4 -vf "select=not(mod(n\,1))" -vsync 0 G:\dataset\video_pick\crop_cut2\guoquan_crop2%05d.png

CUDA_VISIBLE_DEVICES=0 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

## 0130

conda create --name video_audio python=3.10

sudo docker pull registry.cn-beijing.aliyuncs.com/modelscope-repo/modelscope:ubuntu22.04-cuda11.8.0-py310-torch2.1.0-tf2.14.0-1.10.0

./youtube-dl https://g.meituan.com/app/business-live-broadcast/live-detail-new.html?liveid=3220642

## 0131

- 00:03:20 -> 91
- 00:07:08 -> 210
- 00:11:03 -> 330
- 00:19:09 -> 570
- 00:21:02 -> 630
- 00:29:28 -> 871
- 00:36:03 -> 1080
- 00:43:24 -> 1291
- 00:54:17 -> 1621
- 01:01:11 -> 1830
- 01:03:18 -> 1891
- 01:12:14 -> 2160
- 01:23:18 -> 2491
- 01:34:06 -> 2820
- 01:50:12 -> 3300
- 01:56:22 -> 3481
- 02:00:20 -> 3601
- 02:07:07 -> 3810

python -m pip install numpy==1.18.0 --no-build-isolation

crop-video.py --inp /data/log/DaGAN/DaGANTest/cut.mp4

## 0226

分离背景乐用demucs：
https://github.com/jarredou/MVSEP-MDX23-Colab_v2?tab=readme-ov-file

- 大小：256*256像素 Done
- 时间：每段10s左右 Done
- 背景音只能轻微噪声
  - 降噪处理
    - https://www.modelscope.cn/models/damo/speech_dfsmn_ans_psm_48k_causal/summary
  - 说话人二者分离
    - https://www.modelscope.cn/models/damo/speech_campplus_speaker-diarization_common/summary
- 人像不能有遮挡
  - 关键点置信度
  - 炜森遮挡模型使用

pip install funasr==1.


## 0229

- https://github.com/Hillobar/Rope
  - 视频大角度换脸的效果
- https://github.com/facefusion/facefusion?tab=readme-ov-file

python3.10 -m venv facefusion

conda create -name facefusion python=3.10

## 0301

- facefusion
- 音频裁剪
  - 已经有数组[]
    - list：[[5.24, 29.01, 0], [29.29, 37.36, 1]]
    - lsit: [start,end,identity]
  - 从视频中提取出音频为 video_audio
  - 查看0和1的数量
    - 使数量少的为视频人声片段: minor_audio_list
      - minor_audio: [[5.24, 29.01, 0], [29.29, 37.36, 0]]
  - 将原音频video_audio中，次要人声的音频时间段minor_audio_segment用无声音频段代替, 保存为disposed_audio
  - 将disposed_audio放回替换原视频音频 并保存视频

CUDA_VISIBLE_DEVICES=0 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

CUDA_VISIBLE_DEVICES=0 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --master_addr="0.0.0.0" --master_port=12348 run.py --config config/vox-adv-256.yaml --name DaGAN --rgbd --batchsize 12 --kp_num 15 --generator DepthAwareGenerator

---

CUDA_VISIBLE_DEVICES=0 python -m torch.distributed.launch --master_addr="0.0.0.0" --master_port=12348 run.py --config config/vox_serve.yaml --name DaGAN --rgbd --batchsize 12 --kp_num 15 --generator DepthAwareGenerator

opt.device_ids[0]
opt.device_ids=[0, 1, 2, 3]

CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --master_addr="0.0.0.0" --master_port=12348 run.py --config config/vox_serve.yaml --name DaGAN --rgbd --batchsize 20 --kp_num 15 --generator DepthAwareGenerator

CUDA_VISIBLE_DEVICES=0,1,2,3 python -m torch.distributed.launch --nproc_per_node=4 --master_addr="0.0.0.0" --master_port=12348 run.py --config config/vox_serve.yaml --name DaGAN --rgbd --batchsize 20 --kp_num 15 --generator DepthAwareGenerator

## 0304

CUDA_LAUNCH_BLOCKING=1 CUDA_VISIBLE_DEVICES=3 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 3 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

- facefusion
- 音频裁剪
  - 已经有数组[]
    - list：[[5.24, 29.01, 0], [29.29, 37.36, 1]]
    - lsit: [start,end,identity]
  - 从视频中提取出音频为 video_audio
  - 查看0和1的数量
    - 使数量少的为视频人声片段: minor_audio_list
      - minor_audio: [[5.24, 29.01, 0], [29.29, 37.36, 0]]
  - 将原音频video_audio中，次要人声的音频时间段minor_audio_segment用无声音频段代替, 保存为disposed_audio
  - 将disposed_audio放回替换原视频音频 并保存视频

data/anaconda3/envs/modelscope/bin/python

## 0305

- 跑人脸遮挡检测项目

unrar x occlusion_demo.rar -d /data/log/occlusion_demo

kill -9 3757227
kill -9 4158953
kill -9 4170089

## 0308

can you wirte a script fullfill the requests as follows: 

kpt_value: from 0 to 1, get a value every 0.1 gap, total 10 value
min_occlusion_num: from 0~106, get a value every 10 gap, total 10 value
and use these two value into the follow script

python occlusion_annotation.py --input_img_dir /data/log/occlusion_demo/train_data/negtive/ --kpt-thr kpt_value --min-occlusion-num 20
python occlusion_annotation.py --input_img_dir /data/log/occlusion_demo/train_data/posive_part/ --kpt-thr kpt_value --min-occlusion-num 20

and stroage the output from the two script to document output.txt

---

- python occlusion_annotation.py --input_img_dir /data/log/occlusion_demo/train_data/negtive/ --kpt-thr 0.55 --min-occlusion-num 20
- python occlusion_annotation.py --input_img_dir /data/log/occlusion_demo/train_data/posive_part/ --kpt-thr 0.55 --min-occlusion-num 20

## 0309

CUDA_VISIBLE_DEVICES=0 python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 24 --kp_num 15 --generator DepthAwareGenerator

- 越小，扣得越少

python main.py --img_dir /data/log/0119/img --out_dir /data/log/0119/dis_img_150 --color cg --bg /data/log/0119/bg.png --multi_process 30 --mask_th 150

CUDA_VISIBLE_DEVICES=1 python main.py --img_dir /data/log/video_dis/1/ --out_dir /data/log/video_dis/0_dis/ --color cg --bg /data/log/video_dis/bg.png --multi_process 30 --mask_th 0

ffmpeg -i 1.mp4 -start_number 0 -vf "select=between(n\,0\,1800)" -vsync 0 1/%05d.png

python get_seg_video3.py ---path /data/log/video_dis/1_dis/ --video_file 20mask.mp4 --start_id 1 --end_id 1000

python get_seg_video3.py ---path /data/log/video_dis/1_thres/ --video_file thres.mp4 --start_id 1 --end_id 600

python main.py --img_dir /data/log/video_dis/1/ --out_dir /data/log/video_dis/1_thres/ --color g --multi_process 20 --upper 64,159,126 --lower 57,130,98

## 0311

- 初步完成kth+thres值的选取
  - 重配oclusion远程环境
  - 能否输出为表格形式
  - 选择差距最大的两组值
- EMOCA
  - 找出关键点模块
  - 构建原理

sudo mkdir -p /data/log_new/occlusion_demo/

sudo scp -P 56000 -r /data/log/occlusion_demo __su@10.112.226.54:

sudo mkdir -p /data/log/occlusion_demo/

sudo mv /home/__su/occlusion_demo /data/log/

## 0313

--kpt-thr 0.5875 --min-occlusion-num 18

mkdir -p /data/log/occlusion_demo/train_data/error_analyze/neg_0.55_14
mkdir -p /data/log/occlusion_demo/train_data/error_analyze/pos_0.55_14

## 0314

- 数据处理
  - 选中十张代表图
  - 导出关键点信息
    - bbox和关键点的关系
    - 导出后在何处修改
  - 将关键点得分修改
- 数据下载
  - 得到标注格式

- python crop-video.py --inp normal.mp4

CUDA_VISIBLE_DEVICES=1 python demo.py  --config config/vox_serve.yaml --driving_video /data/log/DaGAN/CVPR2022-DaGAN/normal_crop.mp4 --source_image /data/log/DaGAN/CVPR2022-DaGAN/emoca_test.png --checkpoint /data/log/DaGAN/DaGANTest/CVPR22_DaGAN/DaGAN_vox_adv_256.pth.tar --relative --adapt_scale --kp_num 15 --generator DepthAwareGenerator --result_video normal_generation.mp4

ffmpeg -i normal.mp4 -ss 0.0 -t 10.681818181818182 -filter:v "crop=284:285:158:67, scale=256:256" normal_crop.mp4

sudo scp -P 56000 -r /data/log/crop-video/video_env.yml __su@10.112.226.54:/data/log/crop-video

sudo scp -P 56000 -r /data/anaconda3/envs/myenv __su@10.112.226.54:/home/__su/

mv  /home/__su/myenv /home/__su/anaconda3/envs/

sudo scp -P 56000 -r /data/log/DaGAN/DaGANTest/cut.mp4 __su@10.112.226.54:/data/log/crop-video

python main.py --inp cut.mp4

magicmir@2021Sit_admin

conda env export --name myenv > video_env.yml

conda env create -f video_env.yml

sudo scp -P 56000 -r /data/log/DaGAN/CVPR2022-DaGAN/requirements.txt __su@10.112.226.54:/data/log/DaGAN_Serve/

python -m torch.distributed.launch --master_addr="0.0.0.0" --master_port=12348 run.py --config config/vox_serve.yaml --name DaGAN --rgbd --batchsize 12 --kp_num 15 --generator DepthAwareGenerator

conda remove --name work38 --all

set http_proxy=192.168.110.84:6128
set https_proxy=192.168.110.84:6128

python run_dataparallel.py --config config/vox_serve.yaml --device_ids 0 --name DaGAN_model --rgbd --batchsize 1 --kp_num 15 --generator DepthAwareGenerator

pip install tensorboard -i https://pypi.tuna.tsinghua.edu.cn/simple

sudo scp -P 56000 -r /data/log/DaGAN/CVPR2022-DaGAN/run_dataparallel.py __su@10.112.226.54:/data/log/DaGAN_Serve/

python main.py --inp /data/log/crop-video/cut.mp4

### 0316

- python test_emoca_on_images.py

conda env create -f conda-environment_py38_cu11_ubuntu.yml

## 0324

1. 看一下三篇论文概要
   1. 挑一篇研究
2. DaGAN $F_w$ 生成模块研究