# 分类

1. 建立分类模型的一般方法
2. 决策树算法
    - 1）算法框架
    - 2）划分评估：基于熵的方法、基于Gini系数的方法、基于分类误差的方法

3. 分类模型的评估方法（部分内容见课本的第5章）

   - 1）混淆矩阵
   - 2）各种性能指标，包括准确率、错误率、Precision、Recall、P-R曲线、ROC曲线等高
   - 3）评估方法，包括保留法，K-折交叉验证法、自助法等。

4. 分类模型的评估方法 （部分内容见课本的第5章

- 1）混淆矩阵|p303-304,y2|P91-92
- 2）各种性能指标
  - p303-311,y9
  - 准确率|P91
  - 错误率|P91
  - Precision|P181-182
  - Recall|P181-182
  - P-R曲线|p309
  - ROC曲线等高|P182-184

- 3）评估方法，包括保留法，K-折交叉验证法、自助法等。|p312-317,y6|P114-115

分类任务:

通过学习得到一个目标函数(target function), 把每个属性集x映射到一个预先定义的类标号y

## 4.2 解决分类问题的一般方法

建立分类模型的一般方法

- 基本方法
  - Logistic Regression（逻辑回归）
  - Decision Tree based Methods（决策树）
  - Rule-based Methods（基于规则的方法）
  - Nearest-neighbor（近邻方法）
  - Neural Networks（神经网络）
  - Deep Learning（深度学习）
  - Naïve Bayes and Bayesian Belief Networks（贝叶斯方法）
  - Support Vector Machines（支持向量机）
- 集成方法
  - Boosting（提升）
  - Bagging（装袋）
  - Random Forests（随机森林

## 4.2Next 解决分类问题的一般方法

1. 混淆矩阵(confusion matrix)

    定义:

    a confusion matrix, also known as an error matrix,  is a specific table layout that allows visualization of the performance of an algorithm,

    ![20211229124129](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211229124129.png)

    - TPR = $\frac{TP}{TP+FN}$
    - TNR = $\frac{TN}{FP+TN}$

    - FPR = $\frac{FP}{FP+TN}$
    - FNR = $\frac{FN}{TP+FN}$

    accuracy = $\frac{f_{11}+f_{00}}{f_{11}+f_{10}+f_{01}+f_{00}} = \frac{TP+TN}{N}$

    error_rate = $\frac{FP+FN}{N}$

    Precision = $\frac{TP}{TP+FP}$

    Recall(TPR) = $\frac{TP}{TP+FN}$

2. ROC曲线

    接受者操作特征(receive operating characteristic, ROC)曲线是显示分类器真正率(TPR)和假正率(FPR)之间折中的一种图形化方法

    关键点

    - (TPR = 0.FPR =0):把每个实例都预测为负类的模型。
    - (TPR = 1, FPR= 1):把每个实例都预测为正类的模型。
    - (TPR = 1, FPR = 0):理想模型。

    等高: 有相同的TPR,但FPR逐渐变大

    ---
    question:

    ![20211229161934](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211229161934.png)

    ---

    ![20220101114246](https://raw.githubusercontent.com/Logible/Image/main/note_image/20220101114246.png)

3. P-R曲线

    Typically, Precision and Recall are inversely related, ie. as Precision increases, recall falls and vice-versa. A balance between these two needs to be achieved by the IR system, and to achieve this and to compare performance, the precision-recall curves come in handy.

    ![20211229162455](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211229162455.png)

    书本未找到

## 4.3 决策树归纳

### 4.3.1 决策树的工作原理

决策数是一种由结点和有向边组成的层次结构,包括

- root node
- internal node
- leaf node or terminal node

### 4.3.3 表示属性测试条件的方法

- 二元属性
- 标称属性
- 序数属性
- 连续属性

### 4.3.4 选择最佳划分的度量

选择最佳划分的度量通常是根据划分后子女结点不纯(impurity)性的程度

impurity的程度越低, 类分布就越倾斜

选择增益最大的部分

增益: $\Delta = I(parent) - \sum_{j=1}^{k}\frac{N(v_j)}{N}I(v_j)$

- $N(v_j)$是与子女结点$v_j$相关联的记录个数

Gini:

![20211228170644](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228170644.png)

Entropy:

![20211228170704](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228170704.png)

计算熵时, $Olog_20 = 0$

Classification error:

![20211228170741](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228170741.png)

增益率Gain ratio:

![20211228172728](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228172728.png)

SplitINFO

![20211228172821](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228172821.png)

---
question:

决策树算法框架

![20211228173147](https://raw.githubusercontent.com/Logible/Image/main/note_image/20211228173147.png)

---

## 4.5 评估分类器的性能

hold out与k-fold cross validation方法的不足:

由于保留一部分样本用于检验，实际的训练集比D小，因此会引入一些因训练样本规模不同而导致的估计偏差。
leave-one-out方法受训练规模变化的影响较小，但是计算复杂度又太高 。

1. 保持法(hold out)

    将数据集D划分为两个互斥的集合，其中一个作为训练集S，另一个作为检验集T

2. 随机二次抽样

    多次重复保持方法来改进对分类器性能的估计

3. 交叉验证(cross-validation)

   - 二折交叉验证

   选择一个子集作训练集, 而另一个作检验集, 然后交换两个集合的角色

   - k折交叉验证

   把数据分为大小相同的k份, 在每次运行, 选择其中一份作检验集, 该过程重复k次, 使得每份数据都用于检验恰好一次.

   - Leave-one-out（留一法）

   k=n时的k-fold cross validation

4. 自助法(bootstrapping)

    训练记录采用有放回抽样, 即已经选作训练的记录将放回原来的记录集中, 使得它等几率地被重新抽取.

    对于n个样本组成的数据集D，有放回抽样n次，则一个样本始终未被抽中的概率是$(1-\frac{1}{n})^n$，当n足够大时，$(1-\frac{1}{n})^n \to \frac{1}{e} ≈ 0.368$
